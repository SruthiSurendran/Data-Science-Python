{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hrishikesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data=\"\"\"\n",
    "WhatsApp has filed a lawsuit against the Indian government over a ‘traceability’ clause in the new Intermediary Rules 2021, \n",
    "which were notified in February this year. \n",
    "The rules which impact social media intermediaries such as Facebook, WhatsApp, Twitter, \n",
    "and others include a clause wherein companies could be forced to identify the originator of a message or post.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=sent_tokenize(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nWhatsApp has filed a lawsuit against the Indian government over a ‘traceability’ clause in the new Intermediary Rules 2021, \\nwhich were notified in February this year.',\n",
       " 'The rules which impact social media intermediaries such as Facebook, WhatsApp, Twitter, \\nand others include a clause wherein companies could be forced to identify the originator of a message or post.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "words=word_tokenize(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WhatsApp', 'has', 'filed', 'a', 'lawsuit', 'against', 'the', 'Indian', 'government', 'over', 'a', '‘', 'traceability', '’', 'clause', 'in', 'the', 'new', 'Intermediary', 'Rules', '2021', ',', 'which', 'were', 'notified', 'in', 'February', 'this', 'year', '.', 'The', 'rules', 'which', 'impact', 'social', 'media', 'intermediaries', 'such', 'as', 'Facebook', ',', 'WhatsApp', ',', 'Twitter', ',', 'and', 'others', 'include', 'a', 'clause', 'wherein', 'companies', 'could', 'be', 'forced', 'to', 'identify', 'the', 'originator', 'of', 'a', 'message', 'or', 'post', '.']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Converting to smallcase\n",
    "lowercase=[i.lower() for i in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['whatsapp', 'has', 'filed', 'a', 'lawsuit', 'against', 'the', 'indian', 'government', 'over', 'a', '‘', 'traceability', '’', 'clause', 'in', 'the', 'new', 'intermediary', 'rules', '2021', ',', 'which', 'were', 'notified', 'in', 'february', 'this', 'year', '.', 'the', 'rules', 'which', 'impact', 'social', 'media', 'intermediaries', 'such', 'as', 'facebook', ',', 'whatsapp', ',', 'twitter', ',', 'and', 'others', 'include', 'a', 'clause', 'wherein', 'companies', 'could', 'be', 'forced', 'to', 'identify', 'the', 'originator', 'of', 'a', 'message', 'or', 'post', '.']\n"
     ]
    }
   ],
   "source": [
    "print(lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise removal\n",
    "not_required=['the']\n",
    "def noise_removal(data):\n",
    "    words= data.split()\n",
    "    final_text= [i for i in words if i not in not_required]\n",
    "    fial_text = ''.join(text)\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WhatsApp',\n",
       " 'has',\n",
       " 'filed',\n",
       " 'a',\n",
       " 'lawsuit',\n",
       " 'against',\n",
       " 'Indian',\n",
       " 'government',\n",
       " 'over',\n",
       " 'a',\n",
       " '‘traceability’',\n",
       " 'clause',\n",
       " 'in',\n",
       " 'new',\n",
       " 'Intermediary',\n",
       " 'Rules',\n",
       " '2021,',\n",
       " 'which',\n",
       " 'were',\n",
       " 'notified',\n",
       " 'in',\n",
       " 'February',\n",
       " 'this',\n",
       " 'year.',\n",
       " 'The',\n",
       " 'rules',\n",
       " 'which',\n",
       " 'impact',\n",
       " 'social',\n",
       " 'media',\n",
       " 'intermediaries',\n",
       " 'such',\n",
       " 'as',\n",
       " 'Facebook,',\n",
       " 'WhatsApp,',\n",
       " 'Twitter,',\n",
       " 'and',\n",
       " 'others',\n",
       " 'include',\n",
       " 'a',\n",
       " 'clause',\n",
       " 'wherein',\n",
       " 'companies',\n",
       " 'could',\n",
       " 'be',\n",
       " 'forced',\n",
       " 'to',\n",
       " 'identify',\n",
       " 'originator',\n",
       " 'of',\n",
       " 'a',\n",
       " 'message',\n",
       " 'or',\n",
       " 'post.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise_removal(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['WhatsApp', 'has', 'filed', 'a', 'lawsuit', 'against', 'the', 'Indian', 'government', 'over', 'a', 'traceability', 'clause', 'in', 'the', 'new', 'Intermediary', 'Rules', 'which', 'were', 'notified', 'in', 'February', 'this', 'year', 'The', 'rules', 'which', 'impact', 'social', 'media', 'intermediaries', 'such', 'as', 'Facebook', 'WhatsApp', 'Twitter', 'and', 'others', 'include', 'a', 'clause', 'wherein', 'companies', 'could', 'be', 'forced', 'to', 'identify', 'the', 'originator', 'of', 'a', 'message', 'or', 'post']\n"
     ]
    }
   ],
   "source": [
    "## Remove punctuations\n",
    "text=[i for i in words if i.isalpha()]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Hrishikesh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Stemming and Lemmertaization\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Word: buy\n"
     ]
    }
   ],
   "source": [
    "stem= PorterStemmer()\n",
    "lem=WordNetLemmatizer()\n",
    "word = 'buying'\n",
    "print('Stemmed Word:',stem.stem(word))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatized word: buy\n"
     ]
    }
   ],
   "source": [
    "print('lemmatized word:',lem.lemmatize(word,'v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
